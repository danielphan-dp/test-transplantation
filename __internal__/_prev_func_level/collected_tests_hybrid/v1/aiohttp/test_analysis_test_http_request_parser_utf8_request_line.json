{
  "test_name": "test_http_request_parser_utf8_request_line",
  "test_file": "/home/quark-ubuntu-wsl/test_transplantation_cs846_f24/test-transplantation/__internal__/_data/aiohttp/tests/test_http_parser.py",
  "static_methods": [
    {
      "name": "CIMultiDict",
      "source_code": "",
      "file_path": "",
      "line_number": 0
    },
    {
      "name": "URL.build",
      "source_code": "    def build(self, paths, tags=None, wheel_version=None):\n        \"\"\"\n        Build a wheel from files in specified paths, and use any specified tags\n        when determining the name of the wheel.\n        \"\"\"\n        if tags is None:\n            tags = {}",
      "file_path": "/home/quark-ubuntu-wsl/test_transplantation_cs846_f24/test-transplantation/__internal__/_data/aiohttp/venv/lib/python3.9/site-packages/pip/_vendor/distlib/wheel.py",
      "line_number": 363
    },
    {
      "name": "encode",
      "source_code": "    def encode(x):\n        return hashlib.sha224(x.encode()).hexdigest()",
      "file_path": "/home/quark-ubuntu-wsl/test_transplantation_cs846_f24/test-transplantation/__internal__/_data/aiohttp/venv/lib/python3.9/site-packages/pip/_vendor/cachecontrol/caches/file_cache.py",
      "line_number": 103
    },
    {
      "name": "encode",
      "source_code": "    def encode(x):\n        return hashlib.sha224(x.encode()).hexdigest()",
      "file_path": "/home/quark-ubuntu-wsl/test_transplantation_cs846_f24/test-transplantation/__internal__/_data/aiohttp/venv/lib/python3.9/site-packages/pip/_vendor/cachecontrol/caches/file_cache.py",
      "line_number": 103
    }
  ],
  "dynamic_methods": [
    {
      "function": "CIMultiDict",
      "filename": "",
      "line": 0,
      "caller": "test_http_request_parser_utf8_request_line",
      "source_code": ""
    },
    {
      "function": "URL.build",
      "filename": "/home/quark-ubuntu-wsl/test_transplantation_cs846_f24/test-transplantation/__internal__/_data/aiohttp/venv/lib/python3.9/site-packages/pip/_vendor/distlib/wheel.py",
      "line": 363,
      "caller": "test_http_request_parser_utf8_request_line",
      "source_code": "    def build(self, paths, tags=None, wheel_version=None):\n        \"\"\"\n        Build a wheel from files in specified paths, and use any specified tags\n        when determining the name of the wheel.\n        \"\"\"\n        if tags is None:\n            tags = {}\n\n        libkey = list(filter(lambda o: o in paths, ('purelib', 'platlib')))[0]\n        if libkey == 'platlib':\n            is_pure = 'false'\n            default_pyver = [IMPVER]\n            default_abi = [ABI]\n            default_arch = [ARCH]\n        else:\n            is_pure = 'true'\n            default_pyver = [PYVER]\n            default_abi = ['none']\n            default_arch = ['any']\n\n        self.pyver = tags.get('pyver', default_pyver)\n        self.abi = tags.get('abi', default_abi)\n        self.arch = tags.get('arch', default_arch)\n\n        libdir = paths[libkey]\n\n        name_ver = '%s-%s' % (self.name, self.version)\n        data_dir = '%s.data' % name_ver\n        info_dir = '%s.dist-info' % name_ver\n\n        archive_paths = []\n\n        # First, stuff which is not in site-packages\n        for key in ('data', 'headers', 'scripts'):\n            if key not in paths:\n                continue\n            path = paths[key]\n            if os.path.isdir(path):\n                for root, dirs, files in os.walk(path):\n                    for fn in files:\n                        p = fsdecode(os.path.join(root, fn))\n                        rp = os.path.relpath(p, path)\n                        ap = to_posix(os.path.join(data_dir, key, rp))\n                        archive_paths.append((ap, p))\n                        if key == 'scripts' and not p.endswith('.exe'):\n                            with open(p, 'rb') as f:\n                                data = f.read()\n                            data = self.process_shebang(data)\n                            with open(p, 'wb') as f:\n                                f.write(data)\n\n        # Now, stuff which is in site-packages, other than the\n        # distinfo stuff.\n        path = libdir\n        distinfo = None\n        for root, dirs, files in os.walk(path):\n            if root == path:\n                # At the top level only, save distinfo for later\n                # and skip it for now\n                for i, dn in enumerate(dirs):\n                    dn = fsdecode(dn)\n                    if dn.endswith('.dist-info'):\n                        distinfo = os.path.join(root, dn)\n                        del dirs[i]\n                        break\n                assert distinfo, '.dist-info directory expected, not found'\n\n            for fn in files:\n                # comment out next suite to leave .pyc files in\n                if fsdecode(fn).endswith(('.pyc', '.pyo')):\n                    continue\n                p = os.path.join(root, fn)\n                rp = to_posix(os.path.relpath(p, path))\n                archive_paths.append((rp, p))\n\n        # Now distinfo. Assumed to be flat, i.e. os.listdir is enough.\n        files = os.listdir(distinfo)\n        for fn in files:\n            if fn not in ('RECORD', 'INSTALLER', 'SHARED', 'WHEEL'):\n                p = fsdecode(os.path.join(distinfo, fn))\n                ap = to_posix(os.path.join(info_dir, fn))\n                archive_paths.append((ap, p))\n\n        wheel_metadata = [\n            'Wheel-Version: %d.%d' % (wheel_version or self.wheel_version),\n            'Generator: distlib %s' % __version__,\n            'Root-Is-Purelib: %s' % is_pure,\n        ]\n        for pyver, abi, arch in self.tags:\n            wheel_metadata.append('Tag: %s-%s-%s' % (pyver, abi, arch))\n        p = os.path.join(distinfo, 'WHEEL')\n        with open(p, 'w') as f:\n            f.write('\\n'.join(wheel_metadata))\n        ap = to_posix(os.path.join(info_dir, 'WHEEL'))\n        archive_paths.append((ap, p))\n\n        # sort the entries by archive path. Not needed by any spec, but it\n        # keeps the archive listing and RECORD tidier than they would otherwise\n        # be. Use the number of path segments to keep directory entries together,\n        # and keep the dist-info stuff at the end.\n        def sorter(t):\n            ap = t[0]\n            n = ap.count('/')\n            if '.dist-info' in ap:\n                n += 10000\n            return (n, ap)\n        archive_paths = sorted(archive_paths, key=sorter)\n\n        # Now, at last, RECORD.\n        # Paths in here are archive paths - nothing else makes sense.\n        self.write_records((distinfo, info_dir), libdir, archive_paths)\n        # Now, ready to build the zip file\n        pathname = os.path.join(self.dirname, self.filename)\n        self.build_zip(pathname, archive_paths)\n        return pathname\n\n"
    },
    {
      "function": "encode",
      "filename": "/home/quark-ubuntu-wsl/test_transplantation_cs846_f24/test-transplantation/__internal__/_data/aiohttp/venv/lib/python3.9/site-packages/pip/_vendor/cachecontrol/caches/file_cache.py",
      "line": 103,
      "caller": "test_http_request_parser_utf8_request_line",
      "source_code": "    @staticmethod\n    def encode(x):\n        return hashlib.sha224(x.encode()).hexdigest()\n\n"
    },
    {
      "function": "encode",
      "filename": "/home/quark-ubuntu-wsl/test_transplantation_cs846_f24/test-transplantation/__internal__/_data/aiohttp/venv/lib/python3.9/site-packages/pip/_vendor/cachecontrol/caches/file_cache.py",
      "line": 103,
      "caller": "test_http_request_parser_utf8_request_line",
      "source_code": "    @staticmethod\n    def encode(x):\n        return hashlib.sha224(x.encode()).hexdigest()\n\n"
    }
  ],
  "assertions": [
    "assert msg.method == 'GET'",
    "assert msg.path == '/P\u00fcnktchen\\udca0\\udcef\\udcb7'",
    "assert msg.version == (1, 1)",
    "assert msg.headers == CIMultiDict([('STEP', '\u00dfnek\\t\\xa0')])",
    "assert msg.raw_headers == ((b'sTeP', '\u00dfnek\\t\\xa0'.encode()),)",
    "assert not msg.should_close",
    "assert msg.compression is None",
    "assert not msg.upgrade",
    "assert not msg.chunked",
    "assert msg.url == URL.build(path='/P\u00fcnktchen\\udca0\\udcef\\udcb7', encoded=True)"
  ],
  "mocks": [],
  "success": false,
  "test_source_code": "def test_http_request_parser_utf8_request_line(parser: HttpRequestParser) -> None:\n    messages, upgrade, tail = parser.feed_data(\n        # note the truncated unicode sequence\n        b\"GET /P\\xc3\\xbcnktchen\\xa0\\xef\\xb7 HTTP/1.1\\r\\n\" +\n        # for easier grep: ASCII 0xA0 more commonly known as non-breaking space\n        # note the leading and trailing spaces\n        \"sTeP:  \\N{latin small letter sharp s}nek\\t\\N{no-break space}  \"\n        \"\\r\\n\\r\\n\".encode()\n    )\n    msg = messages[0][0]\n\n    assert msg.method == \"GET\"\n    assert msg.path == \"/P\u00fcnktchen\\udca0\\udcef\\udcb7\"\n    assert msg.version == (1, 1)\n    assert msg.headers == CIMultiDict([(\"STEP\", \"\u00dfnek\\t\\xa0\")])\n    assert msg.raw_headers == ((b\"sTeP\", \"\u00dfnek\\t\\xa0\".encode()),)\n    assert not msg.should_close\n    assert msg.compression is None\n    assert not msg.upgrade\n    assert not msg.chunked\n    # python HTTP parser depends on Cython and CPython URL to match\n    # .. but yarl.URL(\"/abs\") is not equal to URL.build(path=\"/abs\"), see #6409\n    assert msg.url == URL.build(path=\"/P\u00fcnktchen\\udca0\\udcef\\udcb7\", encoded=True)"
}