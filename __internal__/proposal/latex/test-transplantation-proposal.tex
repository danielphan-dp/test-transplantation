%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigconf]{acmart}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
% \acmConference[Conference acronym 'XX]{Make sure to enter the correct
%   conference title from your rights confirmation emai}{June 03--05,
%   2018}{Woodstock, NY}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Research Proposal for Test Transplantation}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Ching-Ting Tsai}
\email{c3tsai@uwaterloo.ca}
\affiliation{%
  \institution{University of Waterloo}
  \city{Waterloo}
  \state{Ontario}
  \country{Canada}
}

\author{Duy Phan}
\email{danielphan.dptp@gmail.com}
\affiliation{%
  \institution{University of Waterloo}
  \city{Waterloo}
  \state{Ontario}
  \country{Canada}
}

\author{Yinxi Li}
\email{y3395li@uwaterloo.ca}
\affiliation{%
  \institution{University of Waterloo}
  \city{Waterloo}
  \state{Ontario}
  \country{Canada}
}


%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Trovato et al.}

%% The abstract is a short summary of the work to be presented in the article.
%%
\begin{abstract}
%
Software testing is a crucial task in the development of software, especially for safety-critical and reliability-critical systems.
%
Software testing is an active area of software engineering research~\cite{alshahwan2023_softwaretestingchallenges}.
%
Software transplantation is an emerging area attracting more attention from the research community~\cite{alshahwan2023_softwaretestingchallenges}.
%
Software transplantation techniques can be augmented to transplant unit tests from one project to another. 
%
This research project aims to automate (or semi-automate) the process of unit test transplantation, where unit tests are extracted from a donor project and transplanted into a host project.
%
Retrieval augmented generation (RAG) techniques and available mainstream large language models (LLMs) are the backbone techniques to generate the test code that is tailored to the host project.
%
The ideal generated test code is logically correct, executable and follows all the coding standards of the host project.
%
\end{abstract}
%%


%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
  <concept>
  <concept_id>10011007.10011006.10011008</concept_id>
  <concept_desc>Software and its engineering~Software development techniques</concept_desc>
  <concept_significance>500</concept_significance>
  </concept>
  <concept>
  <concept_id>10003752.10003790.10003792</concept_id>
  <concept_desc>Theory of computation~Program analysis</concept_desc>
  <concept_significance>300</concept_significance>
  </concept>
  <concept>
  <concept_id>10002944.10011123.10011131</concept_id>
  <concept_desc>General and reference~Empirical studies</concept_desc>
  <concept_significance>100</concept_significance>
  </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~Software development techniques}
\ccsdesc[300]{Theory of computation~Program analysis}
\ccsdesc[100]{General and reference~Empirical studies}

%% Paper Key Words
\keywords{Software Testing, Test Transplantation, Large Language Models, Retrieval Augmented Generation}

% \received{20 February 20}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

%%
%% Introduction
%%
\section{Introduction}
%
Software transplantation is an active research area, and when can be done, can be highly useful for developers; it will not only speed up the software development pipeline, but also release a great amount of intensive programming on the developers~\cite{alshahwan2023_softwaretestingchallenges,barr2015_automatedsoftwaretransplantation, sodhi2021_an_insight_on_software_features_supporting_transplantation__a_systematic_review}.
%
Software transplantation aims to extract a feature from one system, referred to as the ``donor program'' and integrate it into another system, the ``host program'' which lacks that feature; some adaptation of the code is expected during the transplantation process~\cite{barr2015_automatedsoftwaretransplantation, sodhi2021_an_insight_on_software_features_supporting_transplantation__a_systematic_review}.
%
In this project, we focus on building a tool for unit test transplantation—transplanting unit tests from one project repository to another that tests the same functionality.
%
By utilizing retrieval augmented generation (RAG) and large language models (LLMs), we aim to develop a system that can potentially save software developers significant time by automating the reuse of unit tests across projects with similar functionality.
%%


\section{Method}
\subsection{Core Tools}
\subsubsection{Database}
Code data is highly dynamic and can be representative, as such, Code understanding is an important and ongoing research problem. In this research project, we will employ more complex embedding algorithms such as CodeBERT and Graph Neural Networks to capture the semantics of the code data. To facilitate retrieval, we will use ChromaDB or FAISS (or similar tools) to store unit test data. The database will store relevant information for each unit test, including the unit test function code, vector embeddings generated by a pre-trained embedding model, and metadata such as the location of the function within the repository. This allows for efficient retrieval of the most relevant unit tests based on a user-defined feature for transplantation.

\subsubsection{Large Language Models and Corresponding APIs}
A large language model (LLM) will play a key role in generating the transplanted unit test code. Given a feature from the donor project and relevant unit test functions, the LLM will help generate the code necessary for transplanting the unit test into the host project. We plan to use models such as Code LLaMA, GPT-4, or other state-of-the-art code-generation models to assist with the transplantation process. There are many LLMs-related tools to take a look at right now (some are somewhat stable, and many are still being developed). If time permits, we will also look at agentic AI tools such as AutoGen or Swarm (which has just been released by OpenAI).

\subsubsection{Retrieval Augmented Generation (RAG)}
\

Retrieval: Given a feature or functionality that the user wishes to transplant, we will retrieve the top k most relevant unit test functions from the donor repository using mathematical techniques such as cosine similarity to compare embeddings.

Function Mapping: After gathering the relevant unit tests from the donor repository, we will search for corresponding code functions in the host repository. These functions are mapped to the donor’s relevant code to ensure a meaningful transplantation.

Augmentation and Generation: The feature code, relevant unit tests from the donor, and mapping functions in the host are then provided to the LLM.

Function Mapping: After gathering the relevant unit tests from the donor repository, we will search for corresponding code functions in the host repository. These functions are mapped to the donor’s relevant code to ensure a meaningful transplantation.

Augmentation and Generation: The feature code, relevant unit tests from the donor, and mapping functions in the host are then provided to the LLM.

With carefully crafted prompts, the LLM will generate the transplanted unit test code, ensuring it is adapted to the host environment.

\subsubsection{Code Graph}
Code graphs are powerful tools for representing and analyzing the structure of software. In our project, we will utilize code graph tools to enhance our understanding of the codebase structure, dependencies, and relationships between different components. This will be particularly useful for:
\begin{itemize}
\item Identifying the relationships between unit tests and the functions they are testing
\item Visualizing the structure of both donor and host projects to aid in the transplantation process
\item Analyzing dependencies to ensure successful integration of transplanted tests
\end{itemize}
We plan to use tools such as Sourcetrail or CodeQL for generating and analyzing code graphs. These tools will provide valuable insights into the structure of the codebase, helping us make more informed decisions during the test transplantation process.

\subsection{Data Preparation and Preprocessing}
%
Unit tests will be extracted from open-source Python repositories (ideally actively maintained and mainstream repositories that are used by millions of developers and large companies), particularly focusing on popular frameworks for general software engineering and web development (front-end or API development frameworks).
%
In addition, we will ensure our research will comply with the license in each repo.

%
Our focus will be on the test directories in each repository (which usually contains all functions used for testing and as in the pytest framework), storing all functions used for unit testing.
%
If time permits, we might also expand to other areas such as command-line interface, machine learning frameworks, and databases; and as well, higher-level testing (file-level and system-level) will also be considered.
%
For code parsing and code structures understanding, code graph tools and syntax trees tools will be used to traverse the code structure and extract relevant information.
%
These extracted unit tests will serve as the primary data for our transplantation process. Extra logic will also be designed to help pinpoint the methods under test associated with the test function.

%
Linting and code formatting tools will be used for data cleansing (such as removing comments and making the code more consistent before adding to the vector database); in addition, the tools are also used to help make the generated tests more consistent with the host project.
%
To enhance the Retrieval-Augmented Generation (RAG) process, we will generate natural language descriptions for each collected test, summarizing their purpose and functionality. This can be achieved using code summarization models or by extracting existing docstrings and comments.
%
The processed code and their corresponding descriptions will then be embedded using models like CodeBERT into a dense feature space, and stored in a vector database such as ChromaDB or FAISS, facilitating efficient retrieval during the test transplantation process.


\subsection{Host Program Analysis}
Extra parsing logic will be designed to identify how the collected unit tests can be transplanted to potential host programs. Host programs can be ongoing high-impact projects that are actively maintained by many developers.

Some possibilities are:
\begin{itemize}
\item Looking at the functions and the associated contexts to identify the tests through retrieval-augmented generation.
\item Scanning through the test suites and the associated contexts to identify the tests that can be transplanted.
\item Applying the aformentioned methods and utilize code graphs to find the correspondence of the tests.
\end{itemize}

\subsection{Prompting}
Some prompting techniques will be researched to help generate the test code that is tailored to the host program.
%
The prompt can be in various forms, in general, the prompt will contain all the necessary context for the LLM to generate the test.
%
In addition, zero-shot, one-shot, few-shot prompting will be utilized to see how the LLMs perform when being provided with some concrete transplantation examples.
%
The examples provided to the LLM can be the motivating examples collected from our research process, in addition, each target repo can also have its own examples.
%
Multi-turn prompting can also be considered to refine the test generation process.
%


\subsection{Evaluation}
The test transplantation pipeline will be benchmarked to see if it can successfully transplant the tests and can outperform a regular test generation process using LLMs.

\subsubsection{Manual Inspection}\label{sec:manual-inspection}
Manual inspection can be used to evaluate the effectiveness of the transplantation process. 
%
Manual inspections can be performed by trying to see if the code is reasonable (for example, if the basic math operations are correct or if the test is for a function that takes in a list, it should not be transplanted to a function that takes in an integer).
%
In addition, the transplanted tests can also then be run to see if they are executable and does not cause any runtime errors in the host program.

\subsubsection{Utilize Code Metrics}\label{sec:utilize-code-metrics}
A combination of code metrics can be used to evaluate the effectiveness of the transplantation.
%
Code coverage and maintainability metrics can be used to evaluate the quality of the tests.
%
If possible, we also wants the generated tests to blend well with the code in the host program (such as following the same coding style and conventions specific to the host program).

\subsubsection{Execute Transplanted Code}\label{sec:execute-transplanted-code}
In a real-world scenario, making the transplanted code executable is important (also, executability can be a priority in the reranking process).
%
The transplanted code should ideally be able to be run without any modifications from the developer.
%
Another research path to look into here is when the generated code is not executable, we can use multi-turn prompting to refine the code to be executable.

\subsubsection{LLM Utilization}\label{sec:llm-utilization}
Another way to evaluate the efffectiveness of the transplantation is to utilize another LLM to review the transplanted code (for example, code quality and code structure of the transplanted code).
%
This approach might require heavy prompt engineering to help capture all the semantics of the code structure.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
\endinput
